{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj02RuSQXqcD96XpabsheZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshi-Ketaki/MLPlayground/blob/main/Statefull_MLMastery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ySlcXtp54Mxz",
        "outputId": "9f3d725f-1e60-48be-f676-9605e245d8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABC -> D\n",
            "BCD -> E\n",
            "CDE -> F\n",
            "DEF -> G\n",
            "EFG -> H\n",
            "FGH -> I\n",
            "GHI -> J\n",
            "HIJ -> K\n",
            "IJK -> L\n",
            "JKL -> M\n",
            "KLM -> N\n",
            "LMN -> O\n",
            "MNO -> P\n",
            "NOP -> Q\n",
            "OPQ -> R\n",
            "PQR -> S\n",
            "QRS -> T\n",
            "RST -> U\n",
            "STU -> V\n",
            "TUV -> W\n",
            "UVW -> X\n",
            "VWX -> Y\n",
            "WXY -> Z\n",
            "23/23 - 2s - loss: 3.2892 - accuracy: 0.0435 - 2s/epoch - 88ms/step\n",
            "23/23 - 0s - loss: 3.2564 - accuracy: 0.0870 - 106ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 3.2396 - accuracy: 0.0870 - 90ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 3.2223 - accuracy: 0.1304 - 88ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 3.2005 - accuracy: 0.1304 - 102ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 3.1667 - accuracy: 0.0435 - 98ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 3.1032 - accuracy: 0.0435 - 91ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 3.0200 - accuracy: 0.0435 - 96ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 2.9615 - accuracy: 0.0435 - 86ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 2.9040 - accuracy: 0.1304 - 97ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 2.8898 - accuracy: 0.1739 - 106ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 2.7782 - accuracy: 0.1304 - 97ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 2.9738 - accuracy: 0.0870 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 3.1587 - accuracy: 0.0000e+00 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.8786 - accuracy: 0.0870 - 71ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.6831 - accuracy: 0.2174 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.6063 - accuracy: 0.1304 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.5921 - accuracy: 0.1739 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.7485 - accuracy: 0.1739 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.6822 - accuracy: 0.0870 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.7738 - accuracy: 0.1304 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.4106 - accuracy: 0.1304 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.3057 - accuracy: 0.2174 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.2075 - accuracy: 0.2609 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.1253 - accuracy: 0.3043 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.2208 - accuracy: 0.2174 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.8962 - accuracy: 0.1304 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.7934 - accuracy: 0.0870 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.1153 - accuracy: 0.3043 - 74ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.1168 - accuracy: 0.1739 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.0906 - accuracy: 0.1304 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.8504 - accuracy: 0.1739 - 65ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.5247 - accuracy: 0.1304 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.9994 - accuracy: 0.5652 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.1037 - accuracy: 0.2174 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 1.9508 - accuracy: 0.4783 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.1042 - accuracy: 0.2609 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 2.0065 - accuracy: 0.3043 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.1272 - accuracy: 0.1304 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.9377 - accuracy: 0.3913 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.8986 - accuracy: 0.2609 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.7835 - accuracy: 0.3913 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.8956 - accuracy: 0.1739 - 65ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.1812 - accuracy: 0.2174 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 1.9365 - accuracy: 0.1304 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.0546 - accuracy: 0.1739 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.7846 - accuracy: 0.2609 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.7147 - accuracy: 0.3913 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.7133 - accuracy: 0.3913 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 1.6224 - accuracy: 0.4348 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.7336 - accuracy: 0.2609 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.7881 - accuracy: 0.2174 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.0985 - accuracy: 0.1739 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5399 - accuracy: 0.6087 - 71ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.4922 - accuracy: 0.6087 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.3772 - accuracy: 0.1739 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.8118 - accuracy: 0.3478 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5470 - accuracy: 0.4348 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5097 - accuracy: 0.4348 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.3994 - accuracy: 0.6957 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.3536 - accuracy: 0.7826 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.6845 - accuracy: 0.3043 - 74ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.4325 - accuracy: 0.4783 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5761 - accuracy: 0.3043 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5363 - accuracy: 0.3478 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5496 - accuracy: 0.3043 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.4352 - accuracy: 0.4783 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.3890 - accuracy: 0.3043 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.2828 - accuracy: 0.6087 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.2551 - accuracy: 0.5652 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 1.1732 - accuracy: 0.7391 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.2653 - accuracy: 0.4783 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.2504 - accuracy: 0.6087 - 86ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.2867 - accuracy: 0.3913 - 100ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.3492 - accuracy: 0.3913 - 102ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.4475 - accuracy: 0.3478 - 92ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.2426 - accuracy: 0.5652 - 84ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.1240 - accuracy: 0.7826 - 92ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.0975 - accuracy: 0.7391 - 93ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.0554 - accuracy: 0.6957 - 96ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.0116 - accuracy: 0.6957 - 94ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.9493 - accuracy: 0.8261 - 101ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.9682 - accuracy: 0.6957 - 95ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.9990 - accuracy: 0.6957 - 107ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 1.3413 - accuracy: 0.3913 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.3513 - accuracy: 0.4348 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.1957 - accuracy: 0.3913 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.1301 - accuracy: 0.6087 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.9305 - accuracy: 0.7826 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8880 - accuracy: 0.8696 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8681 - accuracy: 0.8696 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.9227 - accuracy: 0.6522 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8914 - accuracy: 0.6522 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8846 - accuracy: 0.6957 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.0240 - accuracy: 0.4783 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.2224 - accuracy: 0.4783 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.0808 - accuracy: 0.5652 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8608 - accuracy: 0.8261 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8289 - accuracy: 0.8696 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.9116 - accuracy: 0.6522 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7650 - accuracy: 0.7826 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.7382 - accuracy: 0.8696 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7058 - accuracy: 0.9565 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7116 - accuracy: 0.8261 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7033 - accuracy: 0.8261 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7306 - accuracy: 0.7391 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6913 - accuracy: 0.8696 - 73ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8371 - accuracy: 0.5652 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.5035 - accuracy: 0.4783 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8353 - accuracy: 0.6087 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7727 - accuracy: 0.7391 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6958 - accuracy: 0.7391 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6738 - accuracy: 0.7391 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6121 - accuracy: 0.9130 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5956 - accuracy: 0.9130 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6035 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6114 - accuracy: 0.8696 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7929 - accuracy: 0.6522 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.5716 - accuracy: 0.8696 - 81ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.6359 - accuracy: 0.7391 - 116ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 0.6969 - accuracy: 0.6957 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5710 - accuracy: 0.7826 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5198 - accuracy: 0.9565 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5620 - accuracy: 0.8696 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5519 - accuracy: 0.8696 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5034 - accuracy: 1.0000 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4815 - accuracy: 1.0000 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5949 - accuracy: 0.7391 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5126 - accuracy: 0.8696 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4843 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5968 - accuracy: 0.6957 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6629 - accuracy: 0.7826 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4704 - accuracy: 0.9565 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.0864 - accuracy: 0.4348 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.1601 - accuracy: 0.5652 - 80ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5897 - accuracy: 0.7391 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6189 - accuracy: 0.7391 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 1.0700 - accuracy: 0.3913 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 2.3224 - accuracy: 0.3478 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.7893 - accuracy: 0.6957 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8413 - accuracy: 0.5652 - 71ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5702 - accuracy: 0.9130 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.5222 - accuracy: 0.8696 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4597 - accuracy: 0.9565 - 100ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.4669 - accuracy: 0.9565 - 98ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.4396 - accuracy: 0.9565 - 86ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.4144 - accuracy: 1.0000 - 85ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.4135 - accuracy: 1.0000 - 112ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 0.3886 - accuracy: 1.0000 - 89ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3827 - accuracy: 1.0000 - 92ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3731 - accuracy: 1.0000 - 95ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3620 - accuracy: 1.0000 - 90ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3563 - accuracy: 1.0000 - 114ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 0.3418 - accuracy: 1.0000 - 91ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3389 - accuracy: 1.0000 - 99ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3326 - accuracy: 1.0000 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3212 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3159 - accuracy: 1.0000 - 73ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3059 - accuracy: 1.0000 - 75ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3068 - accuracy: 1.0000 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2974 - accuracy: 1.0000 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2885 - accuracy: 1.0000 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2856 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2770 - accuracy: 1.0000 - 75ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2853 - accuracy: 1.0000 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2640 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2655 - accuracy: 1.0000 - 65ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2608 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2579 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.3044 - accuracy: 0.9565 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2829 - accuracy: 0.9565 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3217 - accuracy: 0.9565 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2786 - accuracy: 0.9565 - 65ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2343 - accuracy: 1.0000 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.3180 - accuracy: 0.9565 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.3761 - accuracy: 0.8696 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6003 - accuracy: 0.7391 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.4216 - accuracy: 0.8261 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3155 - accuracy: 0.9130 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2553 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2891 - accuracy: 0.9565 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4653 - accuracy: 0.7826 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3570 - accuracy: 0.8696 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2936 - accuracy: 0.9130 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2373 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2659 - accuracy: 1.0000 - 76ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4717 - accuracy: 0.7826 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2826 - accuracy: 0.9130 - 71ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2523 - accuracy: 1.0000 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2233 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2961 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.8364 - accuracy: 0.6957 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2425 - accuracy: 1.0000 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2243 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2186 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2983 - accuracy: 0.9130 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.4383 - accuracy: 0.7826 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2273 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2191 - accuracy: 1.0000 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2008 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3331 - accuracy: 0.8261 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3224 - accuracy: 0.8696 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2300 - accuracy: 0.9565 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2731 - accuracy: 0.9565 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2183 - accuracy: 1.0000 - 84ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3310 - accuracy: 0.8696 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2043 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2022 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2469 - accuracy: 0.9565 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3062 - accuracy: 0.8696 - 65ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3936 - accuracy: 0.8261 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2079 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.5146 - accuracy: 0.6957 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3687 - accuracy: 0.8261 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6262 - accuracy: 0.6522 - 53ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.4191 - accuracy: 0.7826 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2543 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.8411 - accuracy: 0.6087 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.3151 - accuracy: 0.8696 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.6088 - accuracy: 0.6957 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.2577 - accuracy: 0.9565 - 87ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.4650 - accuracy: 0.8261 - 97ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 1.6552 - accuracy: 0.5652 - 91ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.7955 - accuracy: 0.6522 - 87ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3310 - accuracy: 0.9565 - 80ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.2891 - accuracy: 0.9565 - 84ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.3297 - accuracy: 0.8261 - 100ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.2986 - accuracy: 0.9565 - 104ms/epoch - 5ms/step\n",
            "23/23 - 0s - loss: 0.2169 - accuracy: 1.0000 - 91ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.2089 - accuracy: 1.0000 - 84ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.1990 - accuracy: 1.0000 - 70ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1902 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1819 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.1800 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1768 - accuracy: 1.0000 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.1731 - accuracy: 1.0000 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.1687 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1627 - accuracy: 1.0000 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.1567 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1516 - accuracy: 1.0000 - 71ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1474 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1439 - accuracy: 1.0000 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1409 - accuracy: 1.0000 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1382 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1357 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1332 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1305 - accuracy: 1.0000 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.1275 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1241 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1204 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1168 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1135 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1106 - accuracy: 1.0000 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.1079 - accuracy: 1.0000 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1053 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1029 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.1006 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0985 - accuracy: 1.0000 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0964 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0944 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.0925 - accuracy: 1.0000 - 80ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0907 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0889 - accuracy: 1.0000 - 65ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0872 - accuracy: 1.0000 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0854 - accuracy: 1.0000 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0837 - accuracy: 1.0000 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0819 - accuracy: 1.0000 - 79ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0802 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.0785 - accuracy: 1.0000 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.0768 - accuracy: 1.0000 - 55ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.0752 - accuracy: 1.0000 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0736 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0720 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0705 - accuracy: 1.0000 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0691 - accuracy: 1.0000 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0677 - accuracy: 1.0000 - 58ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0664 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0651 - accuracy: 1.0000 - 63ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0639 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0627 - accuracy: 1.0000 - 72ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0615 - accuracy: 1.0000 - 69ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0604 - accuracy: 1.0000 - 62ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0593 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0582 - accuracy: 1.0000 - 59ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0572 - accuracy: 1.0000 - 68ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0562 - accuracy: 1.0000 - 57ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.0552 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0543 - accuracy: 1.0000 - 67ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0534 - accuracy: 1.0000 - 66ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0525 - accuracy: 1.0000 - 61ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0516 - accuracy: 1.0000 - 64ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0507 - accuracy: 1.0000 - 60ms/epoch - 3ms/step\n",
            "23/23 - 0s - loss: 0.0499 - accuracy: 1.0000 - 56ms/epoch - 2ms/step\n",
            "23/23 - 0s - loss: 0.0490 - accuracy: 1.0000 - 88ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.0482 - accuracy: 1.0000 - 94ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.0474 - accuracy: 1.0000 - 81ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.0467 - accuracy: 1.0000 - 93ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.0459 - accuracy: 1.0000 - 96ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.0452 - accuracy: 1.0000 - 93ms/epoch - 4ms/step\n",
            "23/23 - 0s - loss: 0.0444 - accuracy: 1.0000 - 93ms/epoch - 4ms/step\n",
            "Model Accuracy: 100.00%\n",
            "['A', 'B', 'C'] -> D\n",
            "['B', 'C', 'D'] -> E\n",
            "['C', 'D', 'E'] -> F\n",
            "['D', 'E', 'F'] -> G\n",
            "['E', 'F', 'G'] -> H\n",
            "['F', 'G', 'H'] -> I\n",
            "['G', 'H', 'I'] -> J\n",
            "['H', 'I', 'J'] -> K\n",
            "['I', 'J', 'K'] -> L\n",
            "['J', 'K', 'L'] -> M\n",
            "['K', 'L', 'M'] -> N\n",
            "['L', 'M', 'N'] -> O\n",
            "['M', 'N', 'O'] -> P\n",
            "['N', 'O', 'P'] -> Q\n",
            "['O', 'P', 'Q'] -> R\n",
            "['P', 'Q', 'R'] -> S\n",
            "['Q', 'R', 'S'] -> T\n",
            "['R', 'S', 'T'] -> U\n",
            "['S', 'T', 'U'] -> V\n",
            "['T', 'U', 'V'] -> W\n",
            "['U', 'V', 'W'] -> X\n",
            "['V', 'W', 'X'] -> Y\n",
            "['W', 'X', 'Y'] -> Z\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'letter = \"K\"\\nseed = [char_to_int[letter]]\\nprint(\"New start: \", letter)\\nfor i in range(0, 5):\\n\\tx = np.reshape(seed, (1, len(seed), 1))\\n\\tx = x / float(len(alphabet))\\n\\tprediction = model.predict(x, verbose=0)\\n\\tindex = np.argmax(prediction)\\n\\tprint(int_to_char[seed[0]], \"->\", int_to_char[index])\\n\\tseed = [index]\\nmodel.reset_states()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Stateful LSTM to learn one-char to one-char mapping\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# fix random seed for reproducibility\n",
        "tf.random.set_seed(7)\n",
        "# define the raw dataset\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "# create mapping of characters to integers (0-25) and the reverse\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "#seq_length = 1\n",
        "seq_length = 3\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(alphabet) - seq_length, 1):\n",
        " seq_in = alphabet[i:i + seq_length]\n",
        " seq_out = alphabet[i + seq_length]\n",
        " dataX.append([char_to_int[char] for char in seq_in])\n",
        " dataY.append(char_to_int[seq_out])\n",
        " print(seq_in, '->', seq_out)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "# default seq length is 1\n",
        "# changing this to 3 to give more context and sequence length to learn from\n",
        "# remember this is similar to giving more timesteps as history setup from earlier\n",
        "X = np.reshape(dataX, (len(dataX), seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(len(alphabet))\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)\n",
        "\n",
        "# create and fit the model\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "# note stateful is set to true\n",
        "model.add(LSTM(50, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "for i in range(300):\n",
        " # do not shuffle data\n",
        " model.fit(X, y, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
        " model.reset_states()\n",
        "\n",
        "# summarize performance of the model\n",
        "scores = model.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
        "model.reset_states()\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# demonstrate some model predictions\n",
        "# seed the first alphabet as starting point\n",
        "'''seed = [char_to_int[alphabet[0]]]\n",
        "for i in range(0, len(alphabet)-1):\n",
        "\tx = np.reshape(seed, (1, len(seed), 1))\n",
        "\tx = x / float(len(alphabet))\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tprint(int_to_char[seed[0]], \"->\", int_to_char[index])\n",
        "  # use current prediction as seed/input for next prediction\n",
        "\tseed = [index]'''\n",
        "\n",
        "\n",
        "# this is when model is using last thrtee timesteps as history\n",
        "for pattern in dataX:\n",
        "  # This is for three timesteps window\n",
        "  #x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\t# This is for three features window\n",
        "  x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(len(alphabet))\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = np.argmax(prediction)\n",
        "  result = int_to_char[index]\n",
        "  seq_in = [int_to_char[value] for value in pattern]\n",
        "  print(seq_in, \"->\", result)\n",
        "model.reset_states()\n",
        "# the above seed i.e. first letter as A, results in correct predictions all over\n",
        "# demonstrate a random starting point\n",
        "# this results on K predictng B and then the remaining is predicted correctly\n",
        "# why :\n",
        "# To truly predict “K,” the state of the network would need to be warmed up and iteratively\n",
        "# fed the letters from “A” to “J.” This reveals that you could achieve the same effect with\n",
        "# a “stateless” LSTM by preparing training data like this:\n",
        "# ---a -> b\n",
        "# --ab -> c\n",
        "# -abc -> d\n",
        "# abcd -> e\n",
        "# commenting this when testing with history\n",
        "'''letter = \"K\"\n",
        "seed = [char_to_int[letter]]\n",
        "print(\"New start: \", letter)\n",
        "for i in range(0, 5):\n",
        "\tx = np.reshape(seed, (1, len(seed), 1))\n",
        "\tx = x / float(len(alphabet))\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tprint(int_to_char[seed[0]], \"->\", int_to_char[index])\n",
        "\tseed = [index]\n",
        "model.reset_states()'''"
      ]
    }
  ]
}